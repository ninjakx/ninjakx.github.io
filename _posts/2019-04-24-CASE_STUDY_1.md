---
layout: post
title: "Real World Application of Time Series ARIMA Model in forecasting"
featured-img: bgtsf
categories: [MACHINE LEARNING]
---
**Objective:**
To Predict SO2 concentration in Dwarka, Delhi region for next few months using ARIMA Model.

**The data has been taken from cpcb website by means of web scraping using selenium and beautifulsoup**

**Code:**
https://github.com/ninjakx/CPCB/blob/master/cpcb.py

**Project Full Code:**
https://github.com/ninjakx/AQP/




```python
from google.colab import drive
drive.mount('/content/drive')
```

    Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
    


```python
%cd drive/My Drive
```

    [Errno 2] No such file or directory: 'drive/My Drive'
    /content/drive/My Drive/AQP-master - Copy (2)/AQP-master/Machine learning
    


```python
%cd AQP-master - Copy (2)/AQP-master/Machine learning
```

    [Errno 2] No such file or directory: 'AQP-master - Copy (2)/AQP-master/Machine learning'
    /content/drive/My Drive/AQP-master - Copy (2)/AQP-master/Machine learning
    


```python
import numpy as np
import pandas as pd
import matplotlib as plt
import warnings
warnings.filterwarnings('ignore')
```


```python
'''arr = ['index.1', 'Nitrogen Dioxide(NO2).1', 'Bar Pressure(Bar Pressure).1',
       'PM 10(RSPM).1', 'PM 2.5(PM2.5).1', 'Sulfur Dioxide(SO2).1',
       'Temperature(TEMP).1']
for i in range(2010,2017):
    data = pd.read_csv("airdata/dwarka-"+str(i)+".csv",sep=';',encoding = 'windows-1252')
    for col in data.columns:
        #print("col:",col)
        if col in arr:
            print(col)
            del data[col]'''
```




    'arr = [\'index.1\', \'Nitrogen Dioxide(NO2).1\', \'Bar Pressure(Bar Pressure).1\',\n       \'PM 10(RSPM).1\', \'PM 2.5(PM2.5).1\', \'Sulfur Dioxide(SO2).1\',\n       \'Temperature(TEMP).1\']\nfor i in range(2010,2017):\n    data = pd.read_csv("airdata/dwarka-"+str(i)+".csv",sep=\';\',encoding = \'windows-1252\')\n    for col in data.columns:\n        #print("col:",col)\n        if col in arr:\n            print(col)\n            del data[col]'




```python
files = ["airdata/dwarka-"+str(i)+".csv" for i in range(2010,2020)]
dfs = [pd.read_csv(fp, sep=';',encoding = 'windows-1252', decimal=',') for fp in files]
#df = pd.concat(dfs).drop_duplicates().reset_index(drop=True)
#print (df)
```


```python
dfs[8]['index'] = dfs[8]['Date']  # 2018
del dfs[8]['Date']
dfs[9]['index'] = dfs[9]['Date']  # 2019
del dfs[9]['Date']
```


```python
import re
def date_extractor(string):
    matches = re.findall('(\d{2,4}[\/\- ]\d{2}[\/\- ]\d{2,4})', string)
    return matches[0]
```


```python
import dateutil
for df1 in dfs:
    df1['index']=df1['index'].astype(str).apply(lambda x: date_extractor(x))
    df1['index']=df1['index'].astype(str).apply(lambda x: dateutil.parser.parse(x))
df = pd.concat(dfs)
```


```python
df = df.rename(columns = {'index':'Date','Bar Pressure(Bar Pressure)':'Bar Pressure(BP)'})
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Bar Pressure(BP)</th>
      <th>Nitrogen Dioxide(NO2)</th>
      <th>PM 10(RSPM)</th>
      <th>PM 2.5(PM2.5)</th>
      <th>Solar Radiation(SR)</th>
      <th>Sulfur Dioxide(SO2)</th>
      <th>Temperature(TEMP)</th>
      <th>Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>646.09</td>
      <td>12.3</td>
      <td>124.12</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5.85</td>
      <td>14.61</td>
      <td>2010-01-02</td>
    </tr>
    <tr>
      <th>1</th>
      <td>732.95</td>
      <td>27.28</td>
      <td>70.62</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5.05</td>
      <td>23.87</td>
      <td>2010-01-03</td>
    </tr>
    <tr>
      <th>2</th>
      <td>735.69</td>
      <td>29.57</td>
      <td>109.88</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>23.84</td>
      <td>31.54</td>
      <td>2010-01-04</td>
    </tr>
    <tr>
      <th>3</th>
      <td>734.58</td>
      <td>15.93</td>
      <td>61.12</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>6.36</td>
      <td>30.12</td>
      <td>2010-01-05</td>
    </tr>
    <tr>
      <th>4</th>
      <td>729.43</td>
      <td>45.35</td>
      <td>163.67</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.42</td>
      <td>34.22</td>
      <td>2010-01-06</td>
    </tr>
  </tbody>
</table>
</div>




```python
data = df[['Bar Pressure(BP)','Nitrogen Dioxide(NO2)','PM 10(RSPM)','PM 2.5(PM2.5)','Solar Radiation(SR)'\
    ,'Sulfur Dioxide(SO2)','Temperature(TEMP)']].groupby([df.Date.dt.year,df.Date.dt.month]).agg('count').rename_axis(['Year','Month'])
```


```python
d = pd.DataFrame(data)
d.columns
```




    Index(['Bar Pressure(BP)', 'Nitrogen Dioxide(NO2)', 'PM 10(RSPM)',
           'PM 2.5(PM2.5)', 'Solar Radiation(SR)', 'Sulfur Dioxide(SO2)',
           'Temperature(TEMP)'],
          dtype='object')




```python
d.unstack()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="10" halign="left">Bar Pressure(BP)</th>
      <th>...</th>
      <th colspan="10" halign="left">Temperature(TEMP)</th>
    </tr>
    <tr>
      <th>Month</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>...</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
    </tr>
    <tr>
      <th>Year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2010</th>
      <td>30</td>
      <td>27</td>
      <td>30</td>
      <td>29</td>
      <td>26</td>
      <td>29</td>
      <td>31</td>
      <td>31</td>
      <td>30</td>
      <td>31</td>
      <td>...</td>
      <td>29</td>
      <td>28</td>
      <td>25</td>
      <td>28</td>
      <td>31</td>
      <td>31</td>
      <td>30</td>
      <td>31</td>
      <td>30</td>
      <td>31</td>
    </tr>
    <tr>
      <th>2011</th>
      <td>31</td>
      <td>27</td>
      <td>29</td>
      <td>28</td>
      <td>31</td>
      <td>30</td>
      <td>31</td>
      <td>31</td>
      <td>30</td>
      <td>31</td>
      <td>...</td>
      <td>29</td>
      <td>28</td>
      <td>31</td>
      <td>30</td>
      <td>31</td>
      <td>31</td>
      <td>30</td>
      <td>31</td>
      <td>30</td>
      <td>29</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>30</td>
      <td>26</td>
      <td>27</td>
      <td>25</td>
      <td>29</td>
      <td>28</td>
      <td>30</td>
      <td>30</td>
      <td>26</td>
      <td>21</td>
      <td>...</td>
      <td>27</td>
      <td>25</td>
      <td>29</td>
      <td>28</td>
      <td>30</td>
      <td>30</td>
      <td>23</td>
      <td>21</td>
      <td>19</td>
      <td>26</td>
    </tr>
    <tr>
      <th>2013</th>
      <td>31</td>
      <td>28</td>
      <td>28</td>
      <td>30</td>
      <td>30</td>
      <td>29</td>
      <td>30</td>
      <td>29</td>
      <td>24</td>
      <td>28</td>
      <td>...</td>
      <td>28</td>
      <td>30</td>
      <td>30</td>
      <td>29</td>
      <td>30</td>
      <td>29</td>
      <td>24</td>
      <td>28</td>
      <td>28</td>
      <td>29</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>31</td>
      <td>28</td>
      <td>31</td>
      <td>29</td>
      <td>30</td>
      <td>29</td>
      <td>29</td>
      <td>31</td>
      <td>30</td>
      <td>30</td>
      <td>...</td>
      <td>31</td>
      <td>29</td>
      <td>30</td>
      <td>29</td>
      <td>29</td>
      <td>31</td>
      <td>30</td>
      <td>30</td>
      <td>30</td>
      <td>29</td>
    </tr>
    <tr>
      <th>2015</th>
      <td>31</td>
      <td>27</td>
      <td>31</td>
      <td>30</td>
      <td>31</td>
      <td>29</td>
      <td>29</td>
      <td>28</td>
      <td>29</td>
      <td>31</td>
      <td>...</td>
      <td>31</td>
      <td>30</td>
      <td>31</td>
      <td>29</td>
      <td>29</td>
      <td>28</td>
      <td>29</td>
      <td>31</td>
      <td>29</td>
      <td>30</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>29</td>
      <td>29</td>
      <td>20</td>
      <td>23</td>
      <td>29</td>
      <td>27</td>
      <td>25</td>
      <td>29</td>
      <td>28</td>
      <td>25</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>30</td>
      <td>29</td>
      <td>30</td>
      <td>29</td>
      <td>30</td>
      <td>25</td>
      <td>30</td>
      <td>31</td>
      <td>30</td>
      <td>30</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>29</td>
      <td>29</td>
      <td>30</td>
      <td>29</td>
      <td>28</td>
      <td>30</td>
      <td>29</td>
      <td>30</td>
      <td>27</td>
      <td>11</td>
    </tr>
    <tr>
      <th>2019</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>21</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>10 rows × 84 columns</p>
</div>



## EDA


```python
bar_pressure = d['Bar Pressure(BP)'].unstack().loc[2012]
bar_pressure
```




    Month
    1     30
    2     26
    3     27
    4     25
    5     29
    6     28
    7     30
    8     30
    9     26
    10    21
    11    19
    12    26
    Name: 2012, dtype: int64




```python
import seaborn as sns
import matplotlib.pyplot as plt
ax = sns.barplot(x = bar_pressure.index, y = bar_pressure.values)
ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha="right")
ax.set(xlabel='months', ylabel='BP values',title='Bar Pressure values for 2012')
```




    [Text(0, 0.5, 'BP values'),
     Text(0.5, 0, 'months'),
     Text(0.5, 1.0, 'Bar Pressure values for 2012')]




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_16_1.png)



```python
ax=d['Bar Pressure(BP)'].unstack().plot.bar(figsize=(20,5),align='edge', width=0.7)
ax.grid(zorder=0)
ax.set(xlabel='months', ylabel='BP values',title='Bar Pressure values for each year by month wise')
#d.unstack(1).plot.barh()
```




    [Text(0, 0.5, 'BP values'),
     Text(0.5, 0, 'months'),
     Text(0.5, 1.0, 'Bar Pressure values for each year by month wise')]




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_17_1.png)



```python
ax=d['Nitrogen Dioxide(NO2)'].unstack().plot.bar(figsize=(20,5),align='edge', width=0.7)
ax.grid(zorder=0)
ax.set(xlabel='months', ylabel='NO2 values',title='NO2 values for each year by month wise')
```




    [Text(0, 0.5, 'NO2 values'),
     Text(0.5, 0, 'months'),
     Text(0.5, 1.0, 'NO2 values for each year by month wise')]




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_18_1.png)



```python
ax=d['PM 10(RSPM)'].unstack().plot.bar(figsize=(20,5),align='edge', width=0.7)
ax.grid(zorder=0)
ax.set(xlabel='months', ylabel='PM 10 values',title='RSPM values for each year by month wise')
```




    [Text(0, 0.5, 'PM 10 values'),
     Text(0.5, 0, 'months'),
     Text(0.5, 1.0, 'RSPM values for each year by month wise')]




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_19_1.png)



```python
ax=d['PM 2.5(PM2.5)'].unstack().plot.bar(figsize=(20,5),align='edge', width=0.7)
ax.grid(zorder=0)
ax.set(xlabel='months', ylabel='PM 2.5 values',title='PM 2.5 values for each year by month wise')
```




    [Text(0, 0.5, 'PM 2.5 values'),
     Text(0.5, 0, 'months'),
     Text(0.5, 1.0, 'PM 2.5 values for each year by month wise')]




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_20_1.png)



```python
ax=d['Solar Radiation(SR)'].unstack().plot.bar(figsize=(20,5),align='edge', width=0.7)
ax.grid(zorder=0)
ax.set(xlabel='months', ylabel='SR values',title='SR values for each year by month wise')
```




    [Text(0, 0.5, 'SR values'),
     Text(0.5, 0, 'months'),
     Text(0.5, 1.0, 'SR values for each year by month wise')]




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_21_1.png)



```python
ax=d['Sulfur Dioxide(SO2)'].unstack().plot.bar(figsize=(20,5),align='edge', width=0.7)
ax.grid(zorder=0)
ax.set(xlabel='months', ylabel='SO2 values',title='SO2 values for each year by month wise')
```




    [Text(0, 0.5, 'SO2 values'),
     Text(0.5, 0, 'months'),
     Text(0.5, 1.0, 'SO2 values for each year by month wise')]




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_22_1.png)



```python
ax=d['Temperature(TEMP)'].unstack().plot.bar(figsize=(20,5),align='edge', width=0.7)
ax.grid(zorder=0)
ax.set(xlabel='months', ylabel='Temp values',title='Temp values for each year by month wise')
```




    [Text(0, 0.5, 'Temp values'),
     Text(0.5, 0, 'months'),
     Text(0.5, 1.0, 'Temp values for each year by month wise')]




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_23_1.png)



```python
def colour_cell(val):
    if val*100/365 < 50:
      color = '#FF6347' 
    elif val*100/365 < 85:
      color = 'yellow'
    else:
      color = '#00FF00'  
    return 'Background-color: %s' % color
```

**Table showing available data for each year**


```python
#d.groupby(['Year','Month'])[['Bar Pressure(Bar Pressure)']].sum()
d.groupby('Year').sum().style.applymap(colour_cell)
```




<style  type="text/css" >
    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col0 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col1 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col2 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col3 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col4 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col5 {
            Background-color:  yellow;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col6 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col0 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col1 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col2 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col3 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col4 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col5 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col6 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col0 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col1 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col2 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col3 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col4 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col5 {
            Background-color:  yellow;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col6 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col0 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col1 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col2 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col3 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col4 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col5 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col6 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col0 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col1 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col2 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col3 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col4 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col5 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col6 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col0 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col1 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col2 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col3 {
            Background-color:  yellow;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col4 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col5 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col6 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col0 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col1 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col2 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col3 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col4 {
            Background-color:  yellow;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col5 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col6 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col0 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col1 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col2 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col3 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col4 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col5 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col6 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col0 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col1 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col2 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col3 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col4 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col5 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col6 {
            Background-color:  #00FF00;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col0 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col1 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col2 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col3 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col4 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col5 {
            Background-color:  #FF6347;
        }    #T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col6 {
            Background-color:  #FF6347;
        }</style><table id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002" ><thead>    <tr>        <th class="blank level0" ></th>        <th class="col_heading level0 col0" >Bar Pressure(BP)</th>        <th class="col_heading level0 col1" >Nitrogen Dioxide(NO2)</th>        <th class="col_heading level0 col2" >PM 10(RSPM)</th>        <th class="col_heading level0 col3" >PM 2.5(PM2.5)</th>        <th class="col_heading level0 col4" >Solar Radiation(SR)</th>        <th class="col_heading level0 col5" >Sulfur Dioxide(SO2)</th>        <th class="col_heading level0 col6" >Temperature(TEMP)</th>    </tr>    <tr>        <th class="index_name level0" >Year</th>        <th class="blank" ></th>        <th class="blank" ></th>        <th class="blank" ></th>        <th class="blank" ></th>        <th class="blank" ></th>        <th class="blank" ></th>        <th class="blank" ></th>    </tr></thead><tbody>
                <tr>
                        <th id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002level0_row0" class="row_heading level0 row0" >2010</th>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col0" class="data row0 col0" >355</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col1" class="data row0 col1" >357</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col2" class="data row0 col2" >354</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col3" class="data row0 col3" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col4" class="data row0 col4" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col5" class="data row0 col5" >302</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row0_col6" class="data row0 col6" >349</td>
            </tr>
            <tr>
                        <th id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002level0_row1" class="row_heading level0 row1" >2011</th>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col0" class="data row1 col0" >358</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col1" class="data row1 col1" >333</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col2" class="data row1 col2" >347</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col3" class="data row1 col3" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col4" class="data row1 col4" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col5" class="data row1 col5" >341</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row1_col6" class="data row1 col6" >358</td>
            </tr>
            <tr>
                        <th id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002level0_row2" class="row_heading level0 row2" >2012</th>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col0" class="data row2 col0" >317</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col1" class="data row2 col1" >148</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col2" class="data row2 col2" >311</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col3" class="data row2 col3" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col4" class="data row2 col4" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col5" class="data row2 col5" >304</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row2_col6" class="data row2 col6" >314</td>
            </tr>
            <tr>
                        <th id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002level0_row3" class="row_heading level0 row3" >2013</th>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col0" class="data row3 col0" >344</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col1" class="data row3 col1" >321</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col2" class="data row3 col2" >354</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col3" class="data row3 col3" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col4" class="data row3 col4" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col5" class="data row3 col5" >354</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row3_col6" class="data row3 col6" >344</td>
            </tr>
            <tr>
                        <th id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002level0_row4" class="row_heading level0 row4" >2014</th>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col0" class="data row4 col0" >358</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col1" class="data row4 col1" >354</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col2" class="data row4 col2" >339</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col3" class="data row4 col3" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col4" class="data row4 col4" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col5" class="data row4 col5" >352</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row4_col6" class="data row4 col6" >357</td>
            </tr>
            <tr>
                        <th id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002level0_row5" class="row_heading level0 row5" >2015</th>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col0" class="data row5 col0" >355</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col1" class="data row5 col1" >326</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col2" class="data row5 col2" >80</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col3" class="data row5 col3" >248</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col4" class="data row5 col4" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col5" class="data row5 col5" >351</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row5_col6" class="data row5 col6" >355</td>
            </tr>
            <tr>
                        <th id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002level0_row6" class="row_heading level0 row6" >2016</th>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col0" class="data row6 col0" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col1" class="data row6 col1" >321</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col2" class="data row6 col2" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col3" class="data row6 col3" >318</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col4" class="data row6 col4" >192</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col5" class="data row6 col5" >319</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row6_col6" class="data row6 col6" >323</td>
            </tr>
            <tr>
                        <th id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002level0_row7" class="row_heading level0 row7" >2017</th>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col0" class="data row7 col0" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col1" class="data row7 col1" >349</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col2" class="data row7 col2" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col3" class="data row7 col3" >326</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col4" class="data row7 col4" >351</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col5" class="data row7 col5" >346</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row7_col6" class="data row7 col6" >351</td>
            </tr>
            <tr>
                        <th id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002level0_row8" class="row_heading level0 row8" >2018</th>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col0" class="data row8 col0" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col1" class="data row8 col1" >328</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col2" class="data row8 col2" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col3" class="data row8 col3" >328</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col4" class="data row8 col4" >328</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col5" class="data row8 col5" >327</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row8_col6" class="data row8 col6" >328</td>
            </tr>
            <tr>
                        <th id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002level0_row9" class="row_heading level0 row9" >2019</th>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col0" class="data row9 col0" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col1" class="data row9 col1" >68</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col2" class="data row9 col2" >0</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col3" class="data row9 col3" >69</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col4" class="data row9 col4" >69</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col5" class="data row9 col5" >69</td>
                        <td id="T_329ee08e_68cb_11e9_ac4c_0242ac1c0002row9_col6" class="data row9 col6" >69</td>
            </tr>
    </tbody></table>



**Observations:**
- By looking at the graphs and statistics we will take NO2 and SO2 concentration from period 2013 to 2017 as number of missing data values are less.

## SO2 concentration in Dwarka


```python
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Bar Pressure(BP)</th>
      <th>Nitrogen Dioxide(NO2)</th>
      <th>PM 10(RSPM)</th>
      <th>PM 2.5(PM2.5)</th>
      <th>Solar Radiation(SR)</th>
      <th>Sulfur Dioxide(SO2)</th>
      <th>Temperature(TEMP)</th>
      <th>Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>646.09</td>
      <td>12.3</td>
      <td>124.12</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5.85</td>
      <td>14.61</td>
      <td>2010-01-02</td>
    </tr>
    <tr>
      <th>1</th>
      <td>732.95</td>
      <td>27.28</td>
      <td>70.62</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5.05</td>
      <td>23.87</td>
      <td>2010-01-03</td>
    </tr>
    <tr>
      <th>2</th>
      <td>735.69</td>
      <td>29.57</td>
      <td>109.88</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>23.84</td>
      <td>31.54</td>
      <td>2010-01-04</td>
    </tr>
    <tr>
      <th>3</th>
      <td>734.58</td>
      <td>15.93</td>
      <td>61.12</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>6.36</td>
      <td>30.12</td>
      <td>2010-01-05</td>
    </tr>
    <tr>
      <th>4</th>
      <td>729.43</td>
      <td>45.35</td>
      <td>163.67</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.42</td>
      <td>34.22</td>
      <td>2010-01-06</td>
    </tr>
  </tbody>
</table>
</div>




```python
data = df.copy()
data.index = pd.to_datetime(data.Date, format='%Y-%m-%d')
data.sort_index(inplace = True)
print(data.index)
```

    DatetimeIndex(['2010-01-02', '2010-01-03', '2010-01-04', '2010-01-05',
                   '2010-01-06', '2010-01-07', '2010-01-08', '2010-01-09',
                   '2010-01-10', '2010-01-11',
                   ...
                   '2019-05-02', '2019-05-04', '2019-06-02', '2019-07-02',
                   '2019-08-02', '2019-09-02', '2019-10-02', '2019-11-02',
                   '2019-12-02', '2019-12-03'],
                  dtype='datetime64[ns]', name='Date', length=3179, freq=None)
    


```python
data.drop(['Date'],axis=1,inplace=True)
```


```python
data = data.convert_objects(convert_numeric=True)
```


```python
data = data.interpolate(method='linear', axis=0).ffill().bfill()
```


```python
import seaborn as sns
import matplotlib as mpl
'''def myFormatter(x, pos):
  return pd.to_datetime(x).strftime('%d/%m/%Y')
plt.figure(figsize=(15,5))
ax=sns.tsplot(data['Sulfur Dioxide(SO2)'].values,time = data.index)
ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(myFormatter))
ax.set(xlabel='Year', ylabel='SO2 values',title='SO2 Concentration')'''
```




    "def myFormatter(x, pos):\n  return pd.to_datetime(x).strftime('%d/%m/%Y')\nplt.figure(figsize=(15,5))\nax=sns.tsplot(data['Sulfur Dioxide(SO2)'].values,time = data.index)\nax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(myFormatter))\nax.set(xlabel='Year', ylabel='SO2 values',title='SO2 Concentration')"




```python
import matplotlib.pyplot as plt 
data1 = data['Sulfur Dioxide(SO2)'].truncate(before = '2013-01-01')
data1 = data['Sulfur Dioxide(SO2)'].truncate(after = '2018-12-01')
#plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%Y'))
#plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=2))
#data1.plot(figsize=(16,5)) 
data1.plot(figsize=(14,5), linewidth=2, fontsize=20)
plt.xlabel('Year', fontsize=20);
plt.title("SO2",fontsize=25)
plt.ylabel("ug/m3",fontsize=20)
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_35_0.png)



```python
# https://www.machinelearningplus.com/time-series/time-series-analysis-python/
# Import Data
df = data.truncate(before = '2013-01-01').copy()
#df.reset_index(inplace=True)

# Prepare data
df['year'] = [d.year for d in df.index]
df['month'] = [d.strftime('%b') for d in df.index]
years = df['year'].unique()

# Draw Plot
fig, axes = plt.subplots(1, 2, figsize=(17,7), dpi= 80)
sns.boxplot(x='year', y='Sulfur Dioxide(SO2)', data=df, ax=axes[0])
sns.boxplot(x='month', y='Sulfur Dioxide(SO2)', data=df.loc[:, :])

# Set Title
axes[0].set_title('Year-wise Box Plot\n(The Trend)', fontsize=18); 
axes[1].set_title('Month-wise Box Plot\n(The Seasonality)', fontsize=18)
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_36_0.png)


- We can see there is low trend which we can ignore. 
- The months of  November and December clearly has higher SO2 concentration, which can be attributed to the festive season.


```python
data_so2 = data.copy()
data_so2=data_so2[['Sulfur Dioxide(SO2)']].truncate(before = '2013-01-01')
data_so2['year'] = data_so2.index.year
data_so2['doy'] = data_so2.index.dayofyear
piv = pd.pivot_table(data_so2,values=['Sulfur Dioxide(SO2)'], index = ['doy'], columns = ['year'])
piv['Sulfur Dioxide(SO2)'].plot(figsize=(15,5),title='SO2')
plt.xlabel('Timestamp')
plt.ylabel('SO2 Concentration')
```




    Text(0, 0.5, 'SO2 Concentration')




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_38_1.png)


### Check if a data set or time series is random by Lag Plot 
A lag plot checks whether a data set or time series is random or not. Random data should not exhibit any identifiable structure in the lag plot. Non-random structure in the lag plot indicates that the underlying data are not random.
It is normally used to check for autocorrelation.


```python
#https://www.itl.nist.gov/div898/handbook/eda/section3/lagplot.htm
from pandas.plotting import lag_plot
lag_plot(data1)
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_40_0.png)


We can see it's less autocorrelated as points get wide and scattered with increasing lags.

Using box plot we can see the outliers.


```python
# library & dataset
import seaborn as sns
# Make boxplot for one group only
sns.boxplot( y=data.values )
#sns.plt.show()

```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f0c766ddeb8>




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_43_1.png)


**Are the data random?** \
No

**Is there serial correlation in the data?** \
No

**Are their outliers in the data?** \
Yes

### Checking randomness in time series using auto-correlation plot of Pandas

Autocorrelation plots are often used for checking randomness in time series. This is done by computing autocorrelations for data values at varying time lags. If time series is random, such autocorrelations should be near zero for any and all time-lag separations. If time series is non-random then one or more of the autocorrelations will be significantly non-zero. The horizontal lines displayed in the plot correspond to 95% and 99% confidence bands. The dashed line is 99% confidence band.


```python
from pandas.plotting import autocorrelation_plot
autocorrelation_plot(data1)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f0c7665bc18>




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_46_1.png)


It resembles to sine waves so it indicates that a value strongly correlates with another data point in the future, hence there is seasonality in the dataset.
And also the data is not random as it gives non zero values for most of the lags.




### Checking Stationality by Summary Statistics



```python
#https://stackoverflow.com/questions/7805552/fitting-a-histogram-with-python
from scipy.stats import norm
import matplotlib.mlab as mlab
import matplotlib.pyplot as plt
'''# Plot histogram
data1.hist()
plt.show()'''

# best fit of data
(mu, sigma) = norm.fit(data1)

# the histogram of the data
n, bins, patches = plt.hist(data1, 60, normed=1, facecolor='green', alpha=0.75)

# add a 'best fit' line
y = mlab.normpdf( bins, mu, sigma)
l = plt.plot(bins, y, 'r--', linewidth=2)

#plot
plt.xlabel('Smarts')
plt.ylabel('Probability')
plt.title(r'$\mathrm{Histogram\ of\ IQ:}\ \mu=%.3f,\ \sigma=%.3f$' %(mu, sigma))
plt.grid(True)

plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_49_0.png)


**Common Probability Distribution**
![alt text](http://blog.cloudera.com/wp-content/uploads/2015/12/distribution.png)

By looking at the above distribution, our data resembles to log normal distribution.

Now split the time series data into two parts and compare the mean variance of each group if they differ and the difference is statistically significant, the time series is likely non-stationary.


```python
X = data1.values
split = int(len(X) / 2)
X1, X2 = X[0:split], X[split:]
mean1, mean2 = X1.mean(), X2.mean()
var1, var2 = X1.var(), X2.var()
print('mean1=%.2f, mean2=%.2f' % (mean1, mean2))
print('variance1=%.2f, variance2=%.2f' % (var1, var2))
```

    mean1=9.34, mean2=10.02
    variance1=81.28, variance2=56.19
    

Mean and Variance of each group differ. Hence it may not be stationary.
Let's take log of the above data since it resembles to the log normal distribution and plot its distribution curve.


```python
X = data1.values
X = np.log(X)
#plt.hist(X)
#plt.title('Distribution after taking log')

# best fit of data
(mu, sigma) = norm.fit(X)

# the histogram of the data
n, bins, patches = plt.hist(X, 60, normed=1, facecolor='green', alpha=0.75)

# add a 'best fit' line
y = mlab.normpdf( bins, mu, sigma)
l = plt.plot(bins, y, 'r--', linewidth=2)

#plot
plt.xlabel('Smarts')
plt.ylabel('Probability')
plt.title(r'$\mathrm{Histogram\ of\ IQ:}\ \mu=%.3f,\ \sigma=%.3f$' %(mu, sigma))
plt.grid(True)

plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_55_0.png)


The distribution looks like a gaussian distribution. So the data is stationary having some stationary component.

### Checking Stationarity by Plotting Rolling Statistics



```python
from statsmodels.tsa.stattools import adfuller
def test_stationarity(timeseries):
    plt.figure(figsize=(14,5))
    #Determing rolling statistics
    rolmean = timeseries.rolling(12).mean()
    rolstd = timeseries.rolling(12).std()

    #Plot rolling statistics:
    orig = plt.plot(timeseries, color='blue',label='Original')
    mean = plt.plot(rolmean, color='red', label='Rolling Mean')
    std = plt.plot(rolstd, color='black', label = 'Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean & Standard Deviation of SO2')
    plt.xlabel('Year', fontsize=20);
    plt.ylabel("ug/m3",fontsize=20)
    plt.show(block=False)
    #Perform Dickey-Fuller test:
    print('Results of Dickey-Fuller Test:')
    dftest = adfuller(timeseries, autolag='AIC')
    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])
    for key,value in dftest[4].items():
        dfoutput['Critical Value (%s)'%key] = value
    print(dfoutput)
    
test_stationarity(data1)
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_58_0.png)


    Results of Dickey-Fuller Test:
    Test Statistic                   -5.443141
    p-value                           0.000003
    #Lags Used                       29.000000
    Number of Observations Used    3070.000000
    Critical Value (1%)              -3.432482
    Critical Value (5%)              -2.862482
    Critical Value (10%)             -2.567271
    dtype: float64
    

Mean and variance are changing so not a stationary time series. There is seasonality present by looking at the graph.

### Checking Stationarity by Augmented Dickey-Fuller test
The Augmented Dickey-Fuller test is a type of statistical test called a unit root test.

The intuition behind a unit root test is that it determines how strongly a time series is defined by a trend.

There are a number of unit root tests and the Augmented Dickey-Fuller may be one of the more widely used. It uses an autoregressive model and optimizes an information criterion across multiple different lag values.

The null hypothesis of the test is that the time series can be represented by a unit root, that it is not stationary (has some time-dependent structure). The alternate hypothesis (rejecting the null hypothesis) is that the time series is stationary.

**Null Hypothesis (H0):** If accepted, it suggests the time series has a unit root, meaning it is non-stationary. It has some time dependent structure.  

**Alternate Hypothesis (H1):** The null hypothesis is rejected; it suggests the time series does not have a unit root, meaning it is stationary. It does not have time-dependent structure. We interpret this result using the p-value from the test. A p-value below a threshold (such as 5% or 1%) suggests we reject the null hypothesis (stationary), otherwise a p-value above the threshold suggests we accept the null hypothesis (non-stationary).

**p-value > 0.05: Accept the null hypothesis (H0), the data has a unit root and is non-stationary.**

**p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.** 

For example, if p-value = 0.2924, it means that null hypothesis will be rejected only around 30% which is quite a high considering the traditional level of significance (1%, 5%, and 10%).


```python
# https://machinelearningmastery.com/time-series-data-stationary-python/
from statsmodels.tsa.stattools import adfuller
X = data1.values
result = adfuller(X)
print('ADF Statistic: %f' % result[0])
print('p-value: %f' % result[1])
print('Critical Values:')
for key, value in result[4].items():
    print('\t%s: %.3f' % (key, value))
```

    ADF Statistic: -5.443141
    p-value: 0.000003
    Critical Values:
    	1%: -3.432
    	5%: -2.862
    	10%: -2.567
    

 test statistic value of -5.443141. The more negative this statistic, the more likely we are to reject the null hypothesis (we have a stationary dataset).

As part of the output, we get a look-up table to help determine the ADF statistic. We can see that our statistic value of -5.443141 is less than the value of -3.432at 1%.

This suggests that **we can reject the null hypothesis with a significance level of less than 1%** (i.e. a low probability that the result is a statistical fluke).

Rejecting the null hypothesis means that the process has no unit root, and in turn that the time series is stationary or does not have time-dependent structure.

### Why do we make the time series stationary?
Auto Regressive’ in ARIMA means it is a linear regression model that uses its own lags as predictors. Linear regression models, as you know, work best when the predictors are not correlated and are independent of each other.

## ESTIMATING THE TREND

### Using rolling average
There are several ways to think about identifying trends in time series. One popular way is by taking a [Rolling average](https://www.datacamp.com/community/tutorials/time-series-analysis-tutorial), which means that, for each time point, you take the average of the points on either side of it. Note that the number of points is specified by a window size, which you need to choose.

What happens then because you take the average is it tends to smooth out noise and seasonality. 

When it comes to determining the window size, here, it makes sense to first try out one of twelve months, as you're talking about yearly seasonality.



```python
fig = plt.figure(figsize=(12,6))
data1.plot(linewidth=2, fontsize=20,label='SO2')
data1.rolling(12).mean().plot(linewidth=2, fontsize=20, color='r',label='Rolling mean')
plt.title("SO2",fontsize=25)
plt.xlabel('Year', fontsize=20)
plt.ylabel("ug/m3",fontsize=20)
plt.legend()
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_66_0.png)


Now you have the trend that you're looking for! You have removed most of the seasonality compared to the previous plot.
But there can still be the seasonality left because the graph shows repeatitive patterns.


### Using Regression method


```python
import matplotlib.pyplot as plt
fig = plt.figure(figsize=(14,6))
from sklearn.linear_model import LinearRegression
model = LinearRegression()
X = [i for i in range(0, len(data1))]
X = np.reshape(X, (len(X), 1))
y = data1
model.fit(X, y)
trend = model.predict(X)
trend = pd.DataFrame(trend)
trend.index = data1.index
# plot trend
plt.plot(y,label='SO2')
plt.plot(trend,label='Trend')
plt.xlabel('Year', fontsize=20);
plt.title("SO2 (Original)",fontsize=25)
plt.ylabel("ug/m3",fontsize=20)
plt.legend()
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_69_0.png)


It shows upward trend.

## ELIMINATING THE TREND

### Transformation

We can use transformation such as log, square root, cube root etc to reduce the trend.


```python
plt.figure(figsize=(14,6))
ts_log = np.log(data1)
plt.plot(ts_log)
plt.xlabel('Year', fontsize=20);
plt.title("SO2 (Log Transformed)",fontsize=25)
plt.ylabel("ug/m3",fontsize=20)
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_74_0.png)


No Trend can be seen after applying log transformation. Before applying log we saw there is high seasonality hence we will focus more on seasonality.

## ELIMINATING SEASONALITY

### Differencing


```python
plt.figure(figsize=(14,6))
ts_log_diff = ts_log - ts_log.shift()
plt.plot(ts_log_diff)
plt.xlabel('Year', fontsize=20);
plt.title("SO2 (Log Transformed + 1st Order Differencing)",fontsize=25)
plt.ylabel("ug/m3",fontsize=20)
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_78_0.png)



```python
ts_log_diff.dropna(inplace=True)
test_stationarity(ts_log_diff)
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_79_0.png)


    Results of Dickey-Fuller Test:
    Test Statistic                  -19.437741
    p-value                           0.000000
    #Lags Used                       29.000000
    Number of Observations Used    3069.000000
    Critical Value (1%)              -3.432483
    Critical Value (5%)              -2.862482
    Critical Value (10%)             -2.567272
    dtype: float64
    

Next we will decompose data into residual, trend

### Decomposition


```python
from statsmodels.tsa.seasonal import seasonal_decompose
plt.figure(figsize=(10,10))
decomposition = seasonal_decompose(ts_log,freq=12)

trend = decomposition.trend
seasonal = decomposition.seasonal
residual = decomposition.resid

plt.subplot(411)
plt.plot(ts_log, label='Original')
plt.legend(loc='best')
plt.subplot(412)
plt.plot(trend, label='Trend')
plt.legend(loc='best')
plt.subplot(413)
plt.plot(seasonal,label='Seasonality')
plt.legend(loc='best')
plt.subplot(414)
plt.plot(residual, label='Residuals')
plt.legend(loc='best')
plt.tight_layout()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_82_0.png)


### Stationary and Non-Stationary Time Series
![time_series](https://www.machinelearningplus.com/wp-content/uploads/2019/02/stationary-and-non-stationary-time-series-1024x674.png)
Source: [R’s TSTutorial](https://cran.r-project.org/web/packages/TSTutorial/vignettes/Stationary.pdf)


```python
import numpy as np, pandas as pd
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import matplotlib.pyplot as plt
plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})

# Import data
df = data1
# Original Series
fig, axes = plt.subplots(3, 2)
axes[0, 0].plot(df.values); axes[0, 0].set_title('Original Series')
plot_acf(df.values, ax=axes[0, 1])
axes[0, 1].set_xlim([0,20])

# 1st Differencing
axes[1, 0].plot(np.diff(df.values)); axes[1, 0].set_title('1st Order Differencing')
plot_acf(np.diff(df.values), ax=axes[1, 1])
axes[1, 1].set_xlim([0,20])

# 2nd Differencing
axes[2, 0].plot(np.diff(np.diff(df.values))); axes[2, 0].set_title('2nd Order Differencing')
plot_acf(np.diff(np.diff(df.values)), ax=axes[2, 1])
axes[2, 1].set_xlim([0,20])
fig.tight_layout()
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_84_0.png)


We will take 1st order differencing as increasing the order can lead to overdifferencing

## ARIMA(p,d,q)


```python
# PACF plot of 1st differenced series
# https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
plt.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})

plt.plot(ts_log.diff()) 
plt.title('1st Differencing')

plot_pacf(ts_log.diff().dropna(),lags=20)
plt.title
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_87_0.png)



![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_87_1.png)


By using Partial Autocorrelation Graph, We can take p value as 1


```python
# PACF plot of 1st differenced series
# https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
plt.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})

plt.plot(ts_log.diff()) 
plt.title('1st Differencing')

plot_acf(ts_log.diff().dropna(),lags=20)
plt.title
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_89_0.png)



![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_89_1.png)


By using Autocorrelation Graph, we can take q = 1


```python
from statsmodels.tsa.arima_model import ARIMA

# 1,1,2 ARIMA Model
model = ARIMA(ts_log,order=(1,1,1))
model_fit = model.fit(disp=0)
print(model_fit.summary())
```

                                   ARIMA Model Results                               
    =================================================================================
    Dep. Variable:     D.Sulfur Dioxide(SO2)   No. Observations:                 3099
    Model:                    ARIMA(1, 1, 1)   Log Likelihood               -2569.272
    Method:                          css-mle   S.D. of innovations              0.554
    Date:                   Sat, 27 Apr 2019   AIC                           5146.544
    Time:                           09:02:51   BIC                           5170.700
    Sample:                                1   HQIC                          5155.219
                                                                                     
    ===============================================================================================
                                      coef    std err          z      P>|z|      [0.025      0.975]
    -----------------------------------------------------------------------------------------------
    const                           0.0003      0.001      0.403      0.687      -0.001       0.002
    ar.L1.D.Sulfur Dioxide(SO2)     0.4312      0.019     22.187      0.000       0.393       0.469
    ma.L1.D.Sulfur Dioxide(SO2)    -0.9533      0.008   -122.400      0.000      -0.969      -0.938
                                        Roots                                    
    =============================================================================
                      Real          Imaginary           Modulus         Frequency
    -----------------------------------------------------------------------------
    AR.1            2.3190           +0.0000j            2.3190            0.0000
    MA.1            1.0490           +0.0000j            1.0490            0.0000
    -----------------------------------------------------------------------------
    


```python
# Plot residual errors
residuals = pd.DataFrame(model_fit.resid)
fig, ax = plt.subplots(1,2)
residuals.plot(title="Residuals", ax=ax[0])
residuals.plot(kind='kde', title='Density', ax=ax[1])
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_92_0.png)



```python
print(residuals.describe())
```

                     0
    count  3099.000000
    mean     -0.000302
    std       0.554533
    min      -2.000433
    25%      -0.285896
    50%      -0.011139
    75%       0.267756
    max       2.657653
    

We are plotting residual to see some trend information not captured by the model.
we get a density plot of the residual error values, suggesting the errors are Gaussian, but may not be centered on zero.


The results shows residual error values are gaussian and is centered on zero.


```python
# Actual vs Fitted
model_fit.plot_predict(dynamic=False)
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_96_0.png)



```python
from statsmodels.tsa.stattools import acf

# Create Training and Test
train = df[:3000]
test = df[3000:]
```


```python
# Build Model
# model = ARIMA(train, order=(3,2,1))  
model = ARIMA(train, order=(1, 1, 1))  
fitted = model.fit(disp=-1)  

# Forecast
fc, se, conf = fitted.forecast(len(test), alpha=0.05)  # 95% conf

# Make as pandas series
fc_series = pd.Series(fc, index=test.index)
lower_series = pd.Series(conf[:, 0], index=test.index)
upper_series = pd.Series(conf[:, 1], index=test.index)

# Plot
plt.figure(figsize=(12,5), dpi=100)
plt.plot(train, label='training')
plt.plot(test, label='actual')
plt.plot(fc_series, label='forecast')
plt.fill_between(lower_series.index, lower_series, upper_series, 
                 color='k', alpha=.15)
plt.title('Forecast vs Actuals')
plt.legend(loc='upper left', fontsize=8)
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_98_0.png)


The reason we are getting straight line as forecast is because there is lot of seasonal components so we will go for SARIMA which uses seasonal differencing.
Seasonal differencing is similar to regular differencing, but, instead of subtracting consecutive terms, you subtract the value from previous season.


```python
df1=df.copy
df=data1
dfseries = ts_log
```


```python
from statsmodels.tsa.stattools import acf

# Create Training and Test
train = dfseries[:3000]
test = dfseries[3000:]
```


```python
import statsmodels.api as sm
mod = sm.tsa.statespace.SARIMAX(dfseries,
                                order=(1, 1, 1),
                                seasonal_order=(1, 1, 1, 6),
                                enforce_stationarity=False,
                                enforce_invertibility=False)

results = mod.fit()

print(results.summary().tables[1])
```

    ==============================================================================
                     coef    std err          z      P>|z|      [0.025      0.975]
    ------------------------------------------------------------------------------
    ar.L1          0.4323      0.015     29.318      0.000       0.403       0.461
    ma.L1         -0.9559      0.006   -161.708      0.000      -0.967      -0.944
    ar.S.L6        0.0385      0.017      2.298      0.022       0.006       0.071
    ma.S.L6       -1.0002      0.051    -19.484      0.000      -1.101      -0.900
    sigma2         0.3063      0.017     17.935      0.000       0.273       0.340
    ==============================================================================
    


```python
results.plot_diagnostics(figsize=(10, 8))
plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_103_0.png)


**how to interpret the plot diagnostics?**

**Top left:** The residual errors seem to fluctuate around a mean of zero and have a uniform variance.

**Top Right:** The density plot suggest normal distribution with mean zero.

**Bottom left:** All the dots should fall perfectly in line with the red line. Any significant deviations would imply the distribution is skewed.

**Bottom Right:** The Correlogram, aka, ACF plot shows the residual errors are not autocorrelated. Any autocorrelation would imply that there is some pattern in the residual errors which are not explained in the model. So you will need to look for more X’s (predictors) to the model.


```python
pred = results.get_prediction(start=3000, dynamic=False)
pred_ci = pred.conf_int()
```


```python
plt.rcParams.update({'figure.figsize':(10,4), 'figure.dpi':120})
ax = np.exp(dfseries).plot(label='observed')
np.exp(pred.predicted_mean).plot(ax=ax, label='One-step ahead Forecast', alpha=.7,color='r')

ax.fill_between(pred_ci.index,
                pred_ci.iloc[:, 0],
                pred_ci.iloc[:, 1], color='k', alpha=.2)

ax.set_xlabel('Date')
ax.set_ylabel('SO2 Levels')
plt.legend()

plt.show()
```


![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_106_0.png)



```python
y_forecasted = pred.predicted_mean
y_truth = test

# Compute the mean square error
mse = ((np.exp(y_forecasted) - np.exp(y_truth)) ** 2).mean()
print('The Mean Squared Error of our forecasts (MSE) is {}'.format(round(mse, 2)))
print('The Root Mean Squared Error of our forecasts (RMSE) is {}'.format(round(mse**0.5, 2)))
```

    The Mean Squared Error of our forecasts (MSE) is 36.42
    The Root Mean Squared Error of our forecasts (RMSE) is 6.03
    


```python
df_err = pd.DataFrame(list(zip(np.exp(y_forecasted),np.exp(y_truth))), index=y_forecasted.index, columns =['Predicted','Actual']) 
df_err 
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Predicted</th>
      <th>Actual</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018-08-19</th>
      <td>8.712283</td>
      <td>16.75</td>
    </tr>
    <tr>
      <th>2018-08-20</th>
      <td>11.458510</td>
      <td>15.44</td>
    </tr>
    <tr>
      <th>2018-08-21</th>
      <td>11.169078</td>
      <td>12.83</td>
    </tr>
    <tr>
      <th>2018-08-22</th>
      <td>10.110420</td>
      <td>11.03</td>
    </tr>
    <tr>
      <th>2018-08-23</th>
      <td>10.013742</td>
      <td>9.77</td>
    </tr>
    <tr>
      <th>2018-08-24</th>
      <td>9.748626</td>
      <td>7.61</td>
    </tr>
    <tr>
      <th>2018-08-25</th>
      <td>8.712044</td>
      <td>7.38</td>
    </tr>
    <tr>
      <th>2018-08-26</th>
      <td>7.950748</td>
      <td>7.12</td>
    </tr>
    <tr>
      <th>2018-08-27</th>
      <td>7.927625</td>
      <td>7.94</td>
    </tr>
    <tr>
      <th>2018-08-28</th>
      <td>8.115069</td>
      <td>10.83</td>
    </tr>
    <tr>
      <th>2018-08-29</th>
      <td>9.846503</td>
      <td>9.47</td>
    </tr>
    <tr>
      <th>2018-08-30</th>
      <td>9.399130</td>
      <td>12.00</td>
    </tr>
    <tr>
      <th>2018-08-31</th>
      <td>10.419743</td>
      <td>10.97</td>
    </tr>
    <tr>
      <th>2018-09-01</th>
      <td>9.469851</td>
      <td>12.64</td>
    </tr>
    <tr>
      <th>2018-09-02</th>
      <td>10.489269</td>
      <td>10.60</td>
    </tr>
    <tr>
      <th>2018-09-03</th>
      <td>9.625009</td>
      <td>19.97</td>
    </tr>
    <tr>
      <th>2018-09-04</th>
      <td>13.572208</td>
      <td>5.65</td>
    </tr>
    <tr>
      <th>2018-09-05</th>
      <td>7.817236</td>
      <td>10.60</td>
    </tr>
    <tr>
      <th>2018-09-06</th>
      <td>10.185522</td>
      <td>6.00</td>
    </tr>
    <tr>
      <th>2018-09-07</th>
      <td>7.395344</td>
      <td>7.76</td>
    </tr>
    <tr>
      <th>2018-09-08</th>
      <td>8.397610</td>
      <td>4.55</td>
    </tr>
    <tr>
      <th>2018-09-09</th>
      <td>6.543036</td>
      <td>11.94</td>
    </tr>
    <tr>
      <th>2018-09-10</th>
      <td>10.050886</td>
      <td>17.55</td>
    </tr>
    <tr>
      <th>2018-09-11</th>
      <td>13.035648</td>
      <td>23.81</td>
    </tr>
    <tr>
      <th>2018-09-13</th>
      <td>14.566187</td>
      <td>8.23</td>
    </tr>
    <tr>
      <th>2018-09-14</th>
      <td>8.645796</td>
      <td>9.89</td>
    </tr>
    <tr>
      <th>2018-09-15</th>
      <td>9.385712</td>
      <td>17.43</td>
    </tr>
    <tr>
      <th>2018-09-16</th>
      <td>12.689951</td>
      <td>17.24</td>
    </tr>
    <tr>
      <th>2018-09-17</th>
      <td>13.372236</td>
      <td>14.90</td>
    </tr>
    <tr>
      <th>2018-09-18</th>
      <td>12.988379</td>
      <td>16.41</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-10-30</th>
      <td>20.887943</td>
      <td>22.04</td>
    </tr>
    <tr>
      <th>2018-10-31</th>
      <td>19.072010</td>
      <td>28.55</td>
    </tr>
    <tr>
      <th>2018-11-01</th>
      <td>21.469495</td>
      <td>7.03</td>
    </tr>
    <tr>
      <th>2018-11-02</th>
      <td>10.368022</td>
      <td>14.44</td>
    </tr>
    <tr>
      <th>2018-11-03</th>
      <td>14.851825</td>
      <td>13.07</td>
    </tr>
    <tr>
      <th>2018-11-04</th>
      <td>14.094758</td>
      <td>5.87</td>
    </tr>
    <tr>
      <th>2018-11-05</th>
      <td>9.880495</td>
      <td>11.59</td>
    </tr>
    <tr>
      <th>2018-11-06</th>
      <td>13.816855</td>
      <td>2.63</td>
    </tr>
    <tr>
      <th>2018-11-07</th>
      <td>6.273186</td>
      <td>8.54</td>
    </tr>
    <tr>
      <th>2018-11-08</th>
      <td>10.539238</td>
      <td>8.01</td>
    </tr>
    <tr>
      <th>2018-11-09</th>
      <td>10.215746</td>
      <td>3.67</td>
    </tr>
    <tr>
      <th>2018-11-10</th>
      <td>6.649106</td>
      <td>14.18</td>
    </tr>
    <tr>
      <th>2018-11-11</th>
      <td>13.438349</td>
      <td>25.10</td>
    </tr>
    <tr>
      <th>2018-11-13</th>
      <td>16.790090</td>
      <td>26.55</td>
    </tr>
    <tr>
      <th>2018-11-14</th>
      <td>18.579586</td>
      <td>21.61</td>
    </tr>
    <tr>
      <th>2018-11-15</th>
      <td>15.824492</td>
      <td>15.72</td>
    </tr>
    <tr>
      <th>2018-11-16</th>
      <td>13.703732</td>
      <td>12.29</td>
    </tr>
    <tr>
      <th>2018-11-17</th>
      <td>12.899622</td>
      <td>15.72</td>
    </tr>
    <tr>
      <th>2018-11-18</th>
      <td>15.150317</td>
      <td>17.29</td>
    </tr>
    <tr>
      <th>2018-11-19</th>
      <td>16.024347</td>
      <td>18.43</td>
    </tr>
    <tr>
      <th>2018-11-20</th>
      <td>16.202653</td>
      <td>16.28</td>
    </tr>
    <tr>
      <th>2018-11-21</th>
      <td>14.390149</td>
      <td>16.51</td>
    </tr>
    <tr>
      <th>2018-11-22</th>
      <td>14.838832</td>
      <td>24.96</td>
    </tr>
    <tr>
      <th>2018-11-23</th>
      <td>18.150540</td>
      <td>27.21</td>
    </tr>
    <tr>
      <th>2018-11-24</th>
      <td>20.076176</td>
      <td>15.02</td>
    </tr>
    <tr>
      <th>2018-11-25</th>
      <td>15.599335</td>
      <td>18.64</td>
    </tr>
    <tr>
      <th>2018-11-26</th>
      <td>16.919921</td>
      <td>25.12</td>
    </tr>
    <tr>
      <th>2018-11-27</th>
      <td>18.566732</td>
      <td>26.36</td>
    </tr>
    <tr>
      <th>2018-11-28</th>
      <td>20.022663</td>
      <td>12.10</td>
    </tr>
    <tr>
      <th>2018-12-01</th>
      <td>13.743775</td>
      <td>10.17</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 2 columns</p>
</div>




```python
df_err.plot(rot=45)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f0c760a48d0>




![png](https://github.com/ninjakx/ninjakx.github.io/raw/master/assets/img/posts/output_109_1.png)


**Conclusion:**

The Mean Squared Error of our forecasts (MSE) is 36.42

The Root Mean Squared Error of our forecasts (RMSE) is 6.03

